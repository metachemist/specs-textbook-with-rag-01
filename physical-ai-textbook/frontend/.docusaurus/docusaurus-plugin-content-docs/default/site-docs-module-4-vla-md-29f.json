{
  "id": "module-4/vla",
  "title": "Vision-Language-Action - Advanced Robotics Applications",
  "description": "Vision-Language-Action (VLA) models represent the cutting edge of robotics AI, combining visual perception, language understanding, and action execution in unified models.",
  "source": "@site/docs/module-4/vla.md",
  "sourceDirName": "module-4",
  "slug": "/module-4/vla",
  "permalink": "/docs/module-4/vla",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4/vla.md",
  "tags": [],
  "version": "current",
  "frontMatter": {},
  "sidebar": "docs",
  "previous": {
    "title": "AI-Robot Brain - Perception and Decision Making",
    "permalink": "/docs/module-3/ai-robot-brain"
  }
}